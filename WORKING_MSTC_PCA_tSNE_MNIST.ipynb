{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"WORKING_MSTC_PCA_tSNE_MNIST.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"cells":[{"metadata":{"id":"Lk_U_0EmotRB","colab_type":"text"},"cell_type":"markdown","source":["\n","<font color=dark face=\"times, serif\" size=6.5>Visualising high-dimensional datasets using PCA and t-SNE in Python</font>\n","\n","### From: Luuk Derksen\n","https://medium.com/@luckylwk/visualising-high-dimensional-datasets-using-pca-and-t-sne-in-python-8ef87e7915b\n","\n","### there are many resources you can check...\n","https://github.com/oreillymedia/t-SNE-tutorial\n","\n","\n","# * [MSTC](http://mstc.ssr.upm.es/big-data-track) and MUIT: <font size=5 color='green'>Deep Learning with Tensorflow & Keras</font>\n"]},{"metadata":{"id":"o7P6Opv6otRE","colab_type":"text"},"cell_type":"markdown","source":["<font color=  #6d3b0c  face=\"times, serif\" size=5>The **MNIST** database of handwritten digits, available from this page, has a training set of 60,000 examples, and a test set of 10,000 examples. It is a subset of a larger set available from NIST. The digits have been size-normalized and centered in a fixed-size image. "]},{"metadata":{"id":"ms8rSOyksSQy","colab_type":"code","colab":{}},"cell_type":"code","source":["import tensorflow as tf\n","mnist = tf.keras.datasets.mnist\n","\n","(X, y),_ = mnist.load_data()\n","X = X / 255.0\n","\n","print('MNIST size: ',X.shape)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"n-zfXRRMtfdU","colab_type":"text"},"cell_type":"markdown","source":["## TO DO...  put X in \"vector\" shape  (60000,784)"]},{"metadata":{"id":"B4iCpOOxsVa3","colab_type":"code","colab":{}},"cell_type":"code","source":["X = X.reshape(???)\n","\n","print('MNIST vector size: ',X.shape)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"cUTLsOAet7cx","colab_type":"text"},"cell_type":"markdown","source":["##  ... TO DO put MNIST X and y into a pandas dataframe with columns:  pixel_1 ... pixel_784  label\n","* ### put labels as strings\n","* ### and \"delete\" X and y from memory (we are not going to use them anymore !)"]},{"metadata":{"id":"NZ-b1gL6otRX","colab_type":"code","colab":{}},"cell_type":"code","source":["import pandas as pd\n","\n","\n","feat_cols = [ 'pixel'+str(i) for i in range(X.shape[1]) ]\n","\n","???\n","\n","print('Size of the dataframe: {}'.format(df.shape))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"cSvGgg3sotRh","colab_type":"text"},"cell_type":"markdown","source":["<font color=  #c5273a  face=\"times, serif\" size=5>============================================<br>\n","**TO DO:** how many examples for each digit?</font>"]},{"metadata":{"id":"mNvzS9GfotRk","colab_type":"code","colab":{}},"cell_type":"code","source":["\n","\n","\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"4ooI0axGotR0","colab_type":"text"},"cell_type":"markdown","source":["###** Because we dont want to be using 60,000 digits in some calculations we’ll take a random subset of the digits. The randomisation is important as the dataset is sorted by its label (i.e., the first seven thousand or so are zeros, etc.). To ensure randomisation we’ll create a random permutation of the number 0 to 69,999 which allows us later to select the first five or ten thousand for our calculations and visualisations.**"]},{"metadata":{"id":"5MaqwUcRotR3","colab_type":"code","colab":{}},"cell_type":"code","source":["import numpy as np\n","\n","rndperm = np.random.permutation(df.shape[0])"],"execution_count":0,"outputs":[]},{"metadata":{"id":"RFf-Tc8gotSA","colab_type":"text"},"cell_type":"markdown","source":["<font color= #792c35 face=\"times, bold\" size=5>The images are all essentially 28-by-28 pixel images and therefore have a total of 784 ‘dimensions’, each holding the value of one specific pixel"]},{"metadata":{"id":"PMcSENh5yl-D","colab_type":"code","colab":{}},"cell_type":"code","source":["%matplotlib inline\n","import matplotlib.pyplot as plt\n","\n","plt.matshow(df.loc[rndperm[9],feat_cols].values.reshape((28,28)).astype(float))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Cr2I57uVotSC","colab_type":"code","colab":{}},"cell_type":"code","source":["\n","# Plot several images\n","plt.gray()\n","fig = plt.figure( figsize=(30,16) )\n","for i in range(0,30):\n","    ax = fig.add_subplot(3,10,i+1, title='Digit: ' + str(df.loc[rndperm[i],'label']) )\n","    ax.matshow(df.loc[rndperm[i],feat_cols].values.reshape((28,28)).astype(float))\n","\n","plt.show()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"NpLo5CGrotSW","colab_type":"text"},"cell_type":"markdown","source":["<font color=   #FF5733   face=\"times, serif\" size=6>============================<br>Dimensionality reduction using PCA from **sklearn**"]},{"metadata":{"id":"wea8oxkQotSX","colab_type":"text"},"cell_type":"markdown","source":["<font color=  #c5273a  face=\"times, serif\" size=5>============================================<br>\n","**TO DO:** Fit PCA to df[feat_cols]</font>"]},{"metadata":{"id":"4QvVBFMkotSa","colab_type":"code","colab":{}},"cell_type":"code","source":["from sklearn.decomposition import PCA\n","\n","\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"25GAWvdNzBnB","colab_type":"code","colab":{}},"cell_type":"code","source":["pca_result.shape"],"execution_count":0,"outputs":[]},{"metadata":{"id":"TiBcZnQH0oT4","colab_type":"code","colab":{}},"cell_type":"code","source":["pca.components_.shape"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Mhcixuoz02wq","colab_type":"code","colab":{}},"cell_type":"code","source":["fig=plt.figure(figsize=(9,3))\n","ax = fig.add_subplot(131)\n","ax.matshow(pca.components_[0].reshape((28,28)))\n","ax = fig.add_subplot(132)\n","ax.matshow(pca.components_[1].reshape((28,28)))\n","ax = fig.add_subplot(133)\n","ax.matshow(pca.components_[2].reshape((28,28)))\n","\n","plt.show()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Po_ub4n2otSg","colab_type":"text"},"cell_type":"markdown","source":["<font color=  #c5273a  face=\"times, serif\" size=5>============================================<br>\n","**TO DO:** Print variance explained</font>"]},{"metadata":{"colab_type":"code","id":"NYs6nAt8M0_-","colab":{}},"cell_type":"code","source":["print(???)\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"4wKWtb3votSo","colab_type":"text"},"cell_type":"markdown","source":["<font color= #792c35 face=\"times, bold\" size=5>Now, given that **the first two components account for about ??%** of the variation in the entire dataset lets see if that is enough to visually set the different digits apart. What we can do is create a scatterplot of the first and second principal component and color each of the different types of digits with a different color. If we are lucky the same type of digits will be positioned (i.e., clustered) together in groups, which would mean that the first two principal components actually tell us a great deal about the specific types of digits."]},{"metadata":{"colab_type":"text","id":"1NI6fUYOMvGx"},"cell_type":"markdown","source":["<font color=  #c5273a  face=\"times, serif\" size=5>============================================<br>\n","**TO DO:** ADD tree columns to df with pca-one -two and -three scores</font>"]},{"metadata":{"id":"Zi8AyfhNotSh","colab_type":"code","colab":{}},"cell_type":"code","source":["df['pca-one'] = pca_result[:,0]\n","df['pca-two'] = pca_result[:,1] \n","df['pca-three'] = pca_result[:,2]\n","\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"qiCxXO2dotSq","colab_type":"code","colab":{}},"cell_type":"code","source":["! pip install ggplot"],"execution_count":0,"outputs":[]},{"metadata":{"id":"-MijNVNlotS0","colab_type":"code","colab":{}},"cell_type":"code","source":["from ggplot import *\n","\n","\n","chart = ggplot( df.loc[rndperm[:3000],:], aes(x='pca-one', y='pca-two', color='label') ) \\\n","        + geom_point(size=75,alpha=0.8) \\\n","        + ggtitle(\"First and Second Principal Components colored by digit\")\n","chart"],"execution_count":0,"outputs":[]},{"metadata":{"id":"YwlIyrtkotS5","colab_type":"text"},"cell_type":"markdown","source":["<font color=   #FF5733   face=\"times, serif\" size=6>=========================================<br>Dimensionality reduction using<br> **t-Distributed Stochastic Neighbouring Entities (t-SNE)**"]},{"metadata":{"id":"wXnuedWhotS8","colab_type":"text"},"cell_type":"markdown","source":["<font color= #792c35 face=\"times, bold\" size=5>t-Distributed stochastic neighbor embedding (t-SNE) minimizes the divergence between two distributions: a distribution that measures pairwise similarities of the input objects and a distribution that measures pairwise similarities of the corresponding low-dimensional points in the embedding."]},{"metadata":{"id":"2Tu0EVbwotS_","colab_type":"text"},"cell_type":"markdown","source":["<font color= #eb0a3a size=5>**LIMITATIONS:**<br>\n","* It is highly recommended to use another dimensionality reduction method (e.g. PCA for dense data or TruncatedSVD for sparse data)to reduce the number of dimensions to a reasonable amount (e.g. 50) if the number of features is very high.<br><br>\n","* Since t-SNE scales quadratically in the number of objects N, its applicability is limited to data sets with **only a few thousand input objects**; beyond that, learning becomes too slow to be practical (and the memory requirements become too large)"]},{"metadata":{"id":"Ff44NDiAotTB","colab_type":"text"},"cell_type":"markdown","source":["<font color= blue size=4>**To make sure we don’t burden our machine in terms of memory and power/time we will only use the first 7,000 samples to run the algorithm on.**"]},{"metadata":{"id":"mgNvF2sootTC","colab_type":"code","colab":{}},"cell_type":"code","source":["import time\n","\n","from sklearn.manifold import TSNE\n","\n","n_sne = 7000\n","\n","time_start = time.time()\n","tsne = TSNE(n_components=2, verbose=1, perplexity=40, n_iter=300)\n","tsne_results = tsne.fit_transform(df.loc[rndperm[:n_sne],feat_cols])\n","\n","print('t-SNE done! Time elapsed: {} seconds'.format(time.time()-time_start))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Eq5kSAvKotTP","colab_type":"text"},"cell_type":"markdown","source":["## t-SNE is a tuneable parameter:\n","\n","<font color= #792c35 face=\"times, bold\" size=5>**“perplexity”** <br>\n","<font size=4.5>which says (loosely) how to balance attention between local and global aspects of your data. The parameter is, in a sense, a guess about the number of close neighbors each point has. The perplexity value has a complex effect on the resulting pictures. The original paper says, “The performance of SNE is fairly robust to changes in the perplexity, and typical values are between 5 and 50.” But the story is more nuanced than that. Getting the most from t-SNE may mean analyzing multiple plots with different perplexities."]},{"metadata":{"id":"qrcQ_7lCotTS","colab_type":"text"},"cell_type":"markdown","source":["<font color= #eb0a3a size=5>How to Use t-SNE Effectively:</font>\n","\n","### Although extremely useful for visualizing high-dimensional data, t-SNE plots can sometimes be mysterious or misleading. By exploring how it behaves in simple cases, we can learn to use it more effectively.\n","See https://distill.pub/2016/misread-tsne/"]},{"metadata":{"id":"07oF4UPhotTW","colab_type":"text"},"cell_type":"markdown","source":["<font color= #792c35 face=\"times, bold\" size=5>... creating a scatter plot of the two dimensions and coloring each sample by its respective label"]},{"metadata":{"id":"gyVjh71votTY","colab_type":"code","colab":{}},"cell_type":"code","source":["df_tsne = df.loc[rndperm[:n_sne],:].copy()\n","df_tsne['x-tsne'] = tsne_results[:,0]\n","df_tsne['y-tsne'] = tsne_results[:,1]\n","\n","chart = ggplot( df_tsne, aes(x='x-tsne', y='y-tsne', color='label') ) \\\n","        + geom_point(size=70,alpha=0.1) \\\n","        + ggtitle(\"tSNE dimensions colored by digit\")\n","chart"],"execution_count":0,"outputs":[]},{"metadata":{"id":"8p0w9AyzotTj","colab_type":"text"},"cell_type":"markdown","source":["<font color= #eb0a3a size=5>If we would now use a **clustering algorithm** to pick out the seperate clusters we could probably quite accurately assign new points to a label."]},{"metadata":{"id":"A30_KHSBotTm","colab_type":"text"},"cell_type":"markdown","source":["<font color=  #c5273a  face=\"times, serif\" size=5>============================================<br>\n","**TO DO: Now take the recommendations and reduce the number of dimensions before feeding the data into the t-SNE algorithm. For this we’ll use PCA again:<br><br>\n","\n","* We will first create a new dataset containing the fifty dimensions generated by the PCA reduction algorithm. We can then use this dataset to perform the t-SNE on\n","</font>"]},{"metadata":{"id":"NGy4WY2KotTp","colab_type":"code","colab":{}},"cell_type":"code","source":["\n","\n","\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"wsx2Q86FotT2","colab_type":"text"},"cell_type":"markdown","source":["### Now lets try and feed this data into the t-SNE algorithm. This time we’ll use 10,000 samples out of the 70,000 to make sure the algorithm does not take up too much memory and CPU. "]},{"metadata":{"id":"-U4h3AVxotT4","colab_type":"code","colab":{}},"cell_type":"code","source":["n_sne = 10000\n","\n","time_start = time.time()\n","\n","tsne = TSNE(n_components=2, verbose=1, perplexity=40, n_iter=300)\n","tsne_pca_results = tsne.fit_transform(pca_result_50[rndperm[:n_sne]])\n","\n","\n","print('t-SNE done! Time elapsed: {} seconds'.format(time.time()-time_start))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"KBbHAJbVotT7","colab_type":"text"},"cell_type":"markdown","source":["<font color=  #c5273a  face=\"times, serif\" size=5>Visualization"]},{"metadata":{"id":"7Gqz7ZQiotT8","colab_type":"code","colab":{}},"cell_type":"code","source":["df_tsne = None\n","df_tsne = df.loc[rndperm[:n_sne],:].copy()\n","df_tsne['x-tsne-pca'] = tsne_pca_results[:,0]\n","df_tsne['y-tsne-pca'] = tsne_pca_results[:,1]\n","\n","chart = ggplot( df_tsne, aes(x='x-tsne-pca', y='y-tsne-pca', color='label') ) \\\n","        + geom_point(size=70,alpha=0.1) \\\n","        + ggtitle(\"tSNE dimensions colored by Digit (PCA)\")\n","chart"],"execution_count":0,"outputs":[]},{"metadata":{"id":"nADIuXFRotUB","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}